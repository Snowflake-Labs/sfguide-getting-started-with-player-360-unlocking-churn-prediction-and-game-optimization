{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a6fe7f-7712-470e-9555-97b0129a9656",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "download_packages",
    "resultHeight": 1558
   },
   "outputs": [],
   "source": [
    "!pip install seaborn\n",
    "!pip install scikit-learn\n",
    "!pip install matplotlib\n",
    "!pip install shap\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "import_packages",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import snowflake.snowpark.functions as F \n",
    "from snowflake.ml.modeling.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "import shap\n",
    "import plotly.graph_objects as go\n",
    "from datetime import timedelta\n",
    "from snowflake.ml.registry import Registry\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "\n",
    "# Add a query tag to the session.\n",
    "session.query_tag = {\"origin\":\"sf_sit-is\", \n",
    "                     \"name\":\"Player_360\", \n",
    "                     \"version\":{\"major\":1, \"minor\":0,},\n",
    "                     \"attributes\":{\"is_quickstart\":1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d89672-8a5a-4fae-be7b-e023e71f021d",
   "metadata": {
    "language": "sql",
    "name": "cell2",
    "resultHeight": 112
   },
   "outputs": [],
   "source": [
    "USE ROLE SYSADMIN;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c18dcf-4682-4e60-9445-b2f59284b59b",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "so_wh",
    "resultHeight": 112
   },
   "outputs": [],
   "source": [
    "session.sql(\"\"\"CREATE OR REPLACE WAREHOUSE so_warehouse WITH\n",
    "  WAREHOUSE_SIZE = 'LARGE'\n",
    "  WAREHOUSE_TYPE = 'SNOWPARK-OPTIMIZED'\n",
    "  RESOURCE_CONSTRAINT = 'MEMORY_16X_X86';\n",
    "\"\"\").collect()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c0e942-9599-4a03-bf0e-6b8b7e3c823f",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "use_wh",
    "resultHeight": 112
   },
   "outputs": [],
   "source": [
    "USE WAREHOUSE so_warehouse;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b549574-9353-4356-9a03-e2c2bea8c6ed",
   "metadata": {
    "collapsed": false,
    "name": "rolling_pred_model",
    "resultHeight": 60
   },
   "source": [
    "## Rolling Predictions Churn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dd4d70-22d1-4c28-9c8a-cc7883cbc6f1",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "sessions_df_pandas",
    "resultHeight": 439
   },
   "outputs": [],
   "source": [
    "# gather session information, point per session information, and purchase information\n",
    "session_points_df = session.sql(\"\"\"\n",
    "SELECT \n",
    "s.session_id,\n",
    "s.user_id,\n",
    "s.log_in,\n",
    "s.session_duration_minutes,\n",
    "s.device_type,\n",
    "ppe.total_points AS total_points_per_session\n",
    "FROM PLAYER_360.RAW.SESSIONS s \n",
    "LEFT JOIN PLAYER_360.ANALYTIC.POINTS_PER_EVENT ppe ON s.session_id = ppe.session_id\n",
    "\"\"\").to_pandas()\n",
    "session_points_df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1873daea-f455-4f76-9a3d-5491e00137f5",
   "metadata": {
    "language": "python",
    "name": "sessions_eda",
    "resultHeight": 287
   },
   "outputs": [],
   "source": [
    "session_points_df['DEVICE_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34784b8d-a016-4171-b2dc-dd5e11f501e7",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "sessions_by_days",
    "resultHeight": 57
   },
   "outputs": [],
   "source": [
    "session_points_df[\"DAY\"] = pd.to_datetime(session_points_df[\"LOG_IN\"].dt.date)\n",
    "# Sort the dataframe by USER_ID and LOG_IN to ensure the rolling window works properly\n",
    "session_points_df = session_points_df.sort_values(by=['USER_ID', 'DAY', 'LOG_IN'])\n",
    "df = session_points_df\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4efee1d-67a9-40d2-94ab-2afab9927ce3",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "window_size",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# set the window size\n",
    "window = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a8ad83-c951-4744-836b-df4c3a3fbf4f",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "group_sessions_by_days",
    "resultHeight": 57
   },
   "outputs": [],
   "source": [
    "day_sessions_df = df.groupby(['USER_ID','DAY']).agg(\n",
    "    total_session_duration=('SESSION_DURATION_MINUTES', 'sum'),\n",
    "    total_sessions=('SESSION_ID', 'count'),\n",
    "    total_points=('TOTAL_POINTS_PER_SESSION', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# for each user add in the days they were active as 0 and inactive as 1\n",
    "day_sessions_df['SESSION_INACTIVE'] = 0\n",
    "\n",
    "day_sessions_df.columns = [u.upper() for u in list(day_sessions_df.columns)]\n",
    "len(day_sessions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9ff359-15de-4876-9611-7c6d4a1c2696",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "first_last_login_by_user",
    "resultHeight": 57
   },
   "outputs": [],
   "source": [
    "# extract the first and last login days for each user to fill the date range \n",
    "# allows for faster computation since we only ahve to go 30 indices back instead of checking if each\n",
    "# DATE object is within 30 days\n",
    "users_logins_df = df.groupby('USER_ID').agg(\n",
    "    first_login_day=('DAY', 'first'),\n",
    "    last_login_day=('DAY', 'last')\n",
    ").reset_index()\n",
    "users_logins_df.columns = [u.upper() for u in list(users_logins_df.columns)]\n",
    "len(users_logins_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f99ba0-9eb1-4627-9c61-c88103f3f76a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "fill_date_range",
    "resultHeight": 57
   },
   "outputs": [],
   "source": [
    "# holds per user, the date range filled sessions information\n",
    "full_day_sessions = []\n",
    "\n",
    "# for each user, fill the date range for that user and merge back into day_sessions_df\n",
    "for _, row in users_logins_df.iterrows():\n",
    "    user_id = row['USER_ID']\n",
    "    start_date = row['FIRST_LOGIN_DAY']\n",
    "    end_date = row['LAST_LOGIN_DAY']\n",
    "   \n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    \n",
    "    user_days_df = pd.DataFrame({'USER_ID': user_id, 'DAY': date_range})\n",
    "    user_day_sessions = pd.merge(user_days_df, day_sessions_df[day_sessions_df['USER_ID'] == user_id], \n",
    "                                 on=['USER_ID', 'DAY'], how='left')\n",
    "\n",
    "    user_day_sessions['TOTAL_SESSION_DURATION'] = user_day_sessions['TOTAL_SESSION_DURATION'].fillna(0)\n",
    "    user_day_sessions['TOTAL_SESSIONS'] = user_day_sessions['TOTAL_SESSIONS'].fillna(0)\n",
    "    user_day_sessions['TOTAL_POINTS'] = user_day_sessions['TOTAL_POINTS'].fillna(0)\n",
    "    user_day_sessions['SESSION_INACTIVE'] = user_day_sessions['SESSION_INACTIVE'].fillna(1)\n",
    "    \n",
    "    full_day_sessions.append(user_day_sessions)\n",
    "\n",
    "day_sessions_df = pd.concat(full_day_sessions).reset_index(drop=True)\n",
    "len(day_sessions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7552b2e5-620e-4653-a903-d6c214d3b285",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "rolling_metrics",
    "resultHeight": 57
   },
   "outputs": [],
   "source": [
    "day_sessions_df['TOTAL_SESSION_DURATION_ROLLING_30_DAYS'] = day_sessions_df.groupby('USER_ID')['TOTAL_SESSION_DURATION'].rolling(\n",
    "    window=window, min_periods=1).sum().reset_index(level=0,drop=True)\n",
    "day_sessions_df['TOTAL_SESSIONS_ROLLING_30_DAYS'] = day_sessions_df.groupby('USER_ID')['TOTAL_SESSIONS'].rolling(\n",
    "    window=window, min_periods=1).sum().reset_index(level=0,drop=True)\n",
    "day_sessions_df['AVERAGE_SESSION_LEN_ROLLING_30_DAYS'] = day_sessions_df['TOTAL_SESSION_DURATION_ROLLING_30_DAYS'] / day_sessions_df['TOTAL_SESSIONS_ROLLING_30_DAYS']\n",
    "day_sessions_df['TOTAL_POINTS_ROLLING_30_DAYS'] = day_sessions_df.groupby('USER_ID')['TOTAL_POINTS'].rolling(\n",
    "    window=window, min_periods=1).sum().reset_index(level=0,drop=True)\n",
    "day_sessions_df['AVERAGE_POINTS_PER_SESSION_ROLLING_30_DAYS'] = day_sessions_df['TOTAL_POINTS_ROLLING_30_DAYS'] / day_sessions_df['TOTAL_SESSIONS_ROLLING_30_DAYS']\n",
    "len(day_sessions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b15680-ba30-4a8a-aaa4-7b37e00a90b5",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "drop_intermediates_sessions",
    "resultHeight": 57
   },
   "outputs": [],
   "source": [
    "rolling_sessions_df = day_sessions_df[['USER_ID', 'DAY', 'SESSION_INACTIVE', \\\n",
    "                                       'TOTAL_SESSION_DURATION_ROLLING_30_DAYS', \\\n",
    "                                      'TOTAL_SESSIONS_ROLLING_30_DAYS', \\\n",
    "                                      'AVERAGE_SESSION_LEN_ROLLING_30_DAYS', \\\n",
    "                                      'TOTAL_POINTS_ROLLING_30_DAYS', \\\n",
    "                                      'AVERAGE_POINTS_PER_SESSION_ROLLING_30_DAYS']]\n",
    "len(rolling_sessions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a05cbe-820b-486d-86b8-f42962fcdc68",
   "metadata": {
    "language": "python",
    "name": "remove_30_days",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "def remove_first_30_days(df):\n",
    "    df = df.sort_values(by=['USER_ID', 'DAY'])\n",
    "    df = df.groupby('USER_ID').apply(lambda x: x.iloc[30:]).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143afca8-4b28-4c3e-aca9-8cc904943949",
   "metadata": {
    "language": "python",
    "name": "remove_30_days_len",
    "resultHeight": 162
   },
   "outputs": [],
   "source": [
    "# remove the first 29 days metrics for each user_id because we want full 30 day averages\n",
    "rolling_sessions_df = remove_first_30_days(rolling_sessions_df)\n",
    "len(rolling_sessions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3539a81e-b264-472e-a03f-e0a5b0e21d91",
   "metadata": {
    "language": "python",
    "name": "user_1001_rolling",
    "resultHeight": 887
   },
   "outputs": [],
   "source": [
    "user_1001_session_information = rolling_sessions_df[rolling_sessions_df['USER_ID'] == 1001]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(user_1001_session_information['DAY'], \n",
    "         user_1001_session_information['TOTAL_SESSION_DURATION_ROLLING_30_DAYS'], label='Total Session Duration (30 days)', color='b', linestyle='-', marker='o')\n",
    "plt.plot(user_1001_session_information['DAY'], \n",
    "         user_1001_session_information['TOTAL_SESSIONS_ROLLING_30_DAYS'], label='Total Sessions (30 days)', color='g', linestyle='-', marker='x')\n",
    "plt.plot(user_1001_session_information['DAY'], \n",
    "         user_1001_session_information['AVERAGE_SESSION_LEN_ROLLING_30_DAYS'], label='Average Session Length (30 days)', color='r', linestyle='-', marker='s')\n",
    "plt.plot(user_1001_session_information['DAY'], \n",
    "         user_1001_session_information['TOTAL_POINTS_ROLLING_30_DAYS'], label='Total Points (30 days)', color='c', linestyle='-', marker='d')\n",
    "plt.plot(user_1001_session_information['DAY'], \n",
    "         user_1001_session_information['AVERAGE_POINTS_PER_SESSION_ROLLING_30_DAYS'], label='Average Points per Session (30 days)', color='m', linestyle='-', marker='^')\n",
    "\n",
    "inactive_mask = user_1001_session_information['SESSION_INACTIVE'] == 1\n",
    "start_day = None\n",
    "end_day = None\n",
    "\n",
    "# Plot shaded regions for inactivity periods\n",
    "for i in range(1, len(user_1001_session_information)):\n",
    "    if inactive_mask[i] and not inactive_mask[i-1]:\n",
    "        # Start of inactivity\n",
    "        start_day = user_1001_session_information['DAY'].iloc[i]\n",
    "    elif not inactive_mask[i] and inactive_mask[i-1]:\n",
    "        # End of inactivity\n",
    "        end_day = user_1001_session_information['DAY'].iloc[i-1]\n",
    "        # Ensure both start_day and end_day are defined before plotting\n",
    "        if start_day is not None and end_day is not None:\n",
    "            plt.axvspan(start_day, end_day, color='gray', alpha=0.3, label='Inactive Period' if i == 1 else \"\")\n",
    "        start_day = None  # Reset start_day after plotting\n",
    "\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Value')\n",
    "plt.yscale('log')\n",
    "plt.title('Rolling Metrics for USER_ID 1001 (30 days)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6161167d-d075-46fc-94e8-294da8abefc3",
   "metadata": {
    "language": "python",
    "name": "get_purchases_df",
    "resultHeight": 252
   },
   "outputs": [],
   "source": [
    "# full dataset of all ads\n",
    "purchases_df = session.table(\"PLAYER_360.RAW.PURCHASES\").to_pandas()\n",
    "purchases_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40c930d-1640-4a5c-80bb-59957aa14a68",
   "metadata": {
    "language": "python",
    "name": "isolate_purchased_df",
    "resultHeight": 252
   },
   "outputs": [],
   "source": [
    "# dataset only of ads that lead to purchases\n",
    "purchased_df = purchases_df[purchases_df['PURCHASE_TYPE'] != 'none']\n",
    "purchased_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5193fe-4ce8-4dde-8316-9ac968f0fb5a",
   "metadata": {
    "language": "python",
    "name": "group_purchases_by_day",
    "resultHeight": 252
   },
   "outputs": [],
   "source": [
    "# get aggregate metrics by day as intermediary to calculate 30 day rolling metrics\n",
    "purchases_df['DAY'] = pd.to_datetime(purchases_df['TIMESTAMP_OF_PURCHASE'].dt.date)\n",
    "day_purchases_df = purchases_df.groupby(['USER_ID', 'DAY']).agg(\n",
    "    total_ad_engagement_time=('AD_ENGAGEMENT_TIME', 'sum'),\n",
    "    total_ad_conversions=('AD_CONVERSION', 'sum'),\n",
    "    total_ads=('AD_INTERACTION_ID', 'count')\n",
    ").reset_index()\n",
    "day_purchases_df['PURCHASE_INACTIVE'] = 0\n",
    "# merge in day_sessions_df to ensure consistency with date_ranges\n",
    "day_purchases_df = pd.merge(day_sessions_df, day_purchases_df, how=\"left\")[list(day_purchases_df.columns)]\n",
    "day_purchases_df[list(day_purchases_df.columns)[:-1]] = day_purchases_df[list(day_purchases_df.columns)[:-1]].fillna(0)\n",
    "day_purchases_df['PURCHASE_INACTIVE'] = day_purchases_df['PURCHASE_INACTIVE'].fillna(1)\n",
    "day_purchases_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23538489-3388-493b-878b-b70318363fd3",
   "metadata": {
    "language": "python",
    "name": "group_purchased_by_day",
    "resultHeight": 404
   },
   "outputs": [],
   "source": [
    "# get aggregate metrics by day as intermediary to calculate 30 day rolling metrics for only purchases\n",
    "purchased_df['DAY'] = pd.to_datetime(purchased_df['TIMESTAMP_OF_PURCHASE'].dt.date)\n",
    "day_purchased_df = purchased_df.groupby(['USER_ID', 'DAY']).agg(\n",
    "    total_purchase_amount=('PURCHASE_AMOUNT', 'sum'),\n",
    "    average_purchase_amount=('PURCHASE_AMOUNT', 'mean'),\n",
    "    total_purchases = ('PURCHASE_ID', 'count')\n",
    ").reset_index()\n",
    "day_purchased_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8548dc11-7fd6-4873-bc08-3bb9b78d1319",
   "metadata": {
    "language": "python",
    "name": "merge_results",
    "resultHeight": 252
   },
   "outputs": [],
   "source": [
    "# now perform final ad and purchase merge\n",
    "result_df = pd.merge(day_purchases_df, day_purchased_df, on=['USER_ID', 'DAY'], how='left').fillna(0)\n",
    "result_df.columns = [u.upper() for u in result_df.columns]\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fa7761-645c-4200-b37e-8975f111a5da",
   "metadata": {
    "language": "python",
    "name": "result_rolling_30_days",
    "resultHeight": 439
   },
   "outputs": [],
   "source": [
    "result_df['TOTAL_PURCHASE_AMOUNT_ROLLING_30_DAYS'] = result_df.groupby('USER_ID')['TOTAL_PURCHASE_AMOUNT'].rolling(window, min_periods=1).sum().reset_index(level=0, drop=True)\n",
    "result_df['TOTAL_PURCHASES_ROLLING_30_DAYS'] = result_df.groupby('USER_ID')['TOTAL_PURCHASES'].rolling(window, min_periods=1).sum().reset_index(level=0, drop=True)\n",
    "result_df['AVG_PURCHASE_AMOUNT_ROLLING_30_DAYS'] = result_df['TOTAL_PURCHASE_AMOUNT_ROLLING_30_DAYS'] / result_df['TOTAL_PURCHASES_ROLLING_30_DAYS']\n",
    "result_df['TOTAL_ADS_ROLLING_30_DAYS'] = result_df.groupby('USER_ID')['TOTAL_ADS'].rolling(window, min_periods=1).sum().reset_index(level=0, drop=True)\n",
    "result_df['AD_CONVERSION_RATE_ROLLING_30_DAYS'] = result_df['TOTAL_PURCHASES_ROLLING_30_DAYS'] /result_df['TOTAL_ADS_ROLLING_30_DAYS']\n",
    "result_df['TOTAL_AD_ENGAGEMENT_TIME_ROLLING_30_DAYS'] = result_df.groupby('USER_ID')['TOTAL_AD_ENGAGEMENT_TIME'].rolling(window, min_periods=1).sum().reset_index(level=0, drop=True)\n",
    "result_df['AVERAGE_ENGAGEMENT_TIME_ROLLING_30_DAYS'] = result_df['TOTAL_AD_ENGAGEMENT_TIME_ROLLING_30_DAYS'] /result_df['TOTAL_ADS_ROLLING_30_DAYS']\n",
    "result_df['AVG_PURCHASE_AMOUNT_ROLLING_30_DAYS'] = result_df['AVG_PURCHASE_AMOUNT_ROLLING_30_DAYS'].fillna(0)\n",
    "result_df['AD_CONVERSION_RATE_ROLLING_30_DAYS'] = result_df['AD_CONVERSION_RATE_ROLLING_30_DAYS'].fillna(0)\n",
    "result_df['AVERAGE_ENGAGEMENT_TIME_ROLLING_30_DAYS'] = result_df['AVERAGE_ENGAGEMENT_TIME_ROLLING_30_DAYS'].fillna(0)\n",
    "result_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6481ca8c-bd4c-461a-b21a-fb3f6a930257",
   "metadata": {
    "language": "python",
    "name": "drop_intermediates",
    "resultHeight": 252
   },
   "outputs": [],
   "source": [
    "# drop the per day metrics and keep only rolling 30 day metrics\n",
    "rolling_purchases_df = result_df[['USER_ID', 'DAY', 'PURCHASE_INACTIVE', \\\n",
    "                                  'TOTAL_PURCHASE_AMOUNT_ROLLING_30_DAYS', \\\n",
    "                                 'TOTAL_PURCHASES_ROLLING_30_DAYS', \\\n",
    "                                 'AVG_PURCHASE_AMOUNT_ROLLING_30_DAYS', \\\n",
    "                                 'TOTAL_ADS_ROLLING_30_DAYS', \\\n",
    "                                 'AD_CONVERSION_RATE_ROLLING_30_DAYS', \\\n",
    "                                 'TOTAL_AD_ENGAGEMENT_TIME_ROLLING_30_DAYS', \\\n",
    "                                 'AVERAGE_ENGAGEMENT_TIME_ROLLING_30_DAYS']]\n",
    "rolling_purchases_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f82a18b-4de3-4834-970a-d607c68201ba",
   "metadata": {
    "language": "python",
    "name": "len_rolling_pruchases_df",
    "resultHeight": 57
   },
   "outputs": [],
   "source": [
    "len(rolling_purchases_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18361527-3745-41cd-9375-85cd7b0bc4ad",
   "metadata": {
    "language": "python",
    "name": "remove_30_days_rolling_purchases",
    "resultHeight": 162
   },
   "outputs": [],
   "source": [
    "rolling_purchases_df = remove_first_30_days(rolling_purchases_df)\n",
    "len(rolling_purchases_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8713fb62-8e82-467d-9fe2-518f1b977e52",
   "metadata": {
    "language": "python",
    "name": "merge_sessions_purchases",
    "resultHeight": 252
   },
   "outputs": [],
   "source": [
    "# merge sessions and purchases information to have final features dataframe for model training\n",
    "features_df = pd.merge(rolling_sessions_df, rolling_purchases_df, on=[\"USER_ID\",\"DAY\"], how=\"outer\")\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5c2e16-eefe-4f0d-ae0d-01d7074c9bfe",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "compress_data_size",
    "resultHeight": 259
   },
   "outputs": [],
   "source": [
    "features_df['USER_ID'] = features_df['USER_ID'].astype('int32')\n",
    "\n",
    "binary_list = ['SESSION_INACTIVE', 'PURCHASE_INACTIVE']\n",
    "features_df[binary_list] = features_df[binary_list].astype('int8')\n",
    "\n",
    "integer_columns = [u for u in features_df.columns if 'TOTAL' in u] + ['USER_ID'] \n",
    "integer_columns = [col for col in integer_columns  if 'TOTAL_POINTS_ROLLING_30_DAYS' != col] \n",
    "integer_columns\n",
    "features_df[integer_columns] = features_df[integer_columns].astype('int32')\n",
    "\n",
    "float_columns = set(features_df.columns) - set(integer_columns) - set(binary_list) - set(['DAY'])\n",
    "features_df[list(float_columns)] = features_df[list(float_columns)].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f405b6-8865-4bdb-b4f4-b3fc659c5cf7",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "calculate_label",
    "resultHeight": 0
   },
   "outputs": [],
   "source": "# Function to compute whether a user logged in in the next 7 days, used for churn labeling\ndef calculate_login_within_7_days(user_data):\n    # Sum the 'SESSION_INACTIVE' values for the next 7 days (excluding current day)\n    user_data.loc[:, 'future_sessions_sum'] = user_data['SESSION_INACTIVE'].shift(-7).rolling(window=7, min_periods=1).sum()\n\n    # If the sum is less than 7, then the user logged in within the next 7 days\n    user_data.loc[:, 'LOGIN_NEXT_7_DAYS'] = (user_data['future_sessions_sum'] < 7).astype(int)\n\n    # Drop the temporary 'future_sessions_sum' column, if not needed\n    user_data.drop(columns=['future_sessions_sum'], inplace=True)\n\n    return user_data\n\n# Sort the data by USER_ID and DAY\nfeatures_df = features_df.sort_values(by=['USER_ID', 'DAY'])\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aca948-fdc6-4a3e-b820-6f8f9fd25282",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "create_labels",
    "resultHeight": 544
   },
   "outputs": [],
   "source": "features_df['LOGIN_NEXT_7_DAYS'] = 0\nfeatures_df['LOGIN_NEXT_7_DAYS'] = features_df['LOGIN_NEXT_7_DAYS'].astype(int)\nfeatures_df['LOGIN_NEXT_7_DAYS'] = features_df.groupby('USER_ID', group_keys=False).apply(calculate_login_within_7_days)['LOGIN_NEXT_7_DAYS']\nfeatures_df.head(100)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a727309b-c19d-4f78-8600-3258fe90060a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "predicted_df",
    "resultHeight": 357
   },
   "outputs": [],
   "source": [
    "# remove the currently active users from the dataset as the users to predict\n",
    "retention_df = session.table(\"PLAYER_360.ANALYTIC.RETENTION\").to_pandas()\n",
    "active_users = retention_df[retention_df['CHURNED'] == 0]\n",
    "df1_filtered = features_df[features_df['USER_ID'].isin(active_users['USER_ID'])]\n",
    "df1_filtered = df1_filtered.sort_values(by=['USER_ID', 'DAY'])\n",
    "to_pred_df = df1_filtered.groupby('USER_ID').apply(lambda x: x.iloc[-1]).reset_index(drop=True)\n",
    "\n",
    "# this is the dataset to predicted with our final trained and tested model\n",
    "to_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6d42fe-1910-4fd4-a9fa-b6d98b2878c7",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "removed_to_pred_df",
    "resultHeight": 57
   },
   "outputs": [],
   "source": [
    "# remove from features this dataset of currently active users\n",
    "mask = features_df[['USER_ID', 'DAY']].isin(to_pred_df[['USER_ID', 'DAY']]).all(axis=1)\n",
    "features_df = features_df[~mask]\n",
    "len(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14384e0-92e5-465c-be6f-efd7eda2fc12",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "finalized_features_df",
    "resultHeight": 252
   },
   "outputs": [],
   "source": [
    "final_features_df = features_df.drop(labels=['USER_ID', 'DAY', 'SESSION_INACTIVE', 'PURCHASE_INACTIVE'], axis=1)\n",
    "final_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70820c-3b1d-4679-bb16-c456cc098020",
   "metadata": {
    "collapsed": false,
    "name": "eda",
    "resultHeight": 74
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce3c588-9ce4-4465-91ff-152aacd9d627",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "final_features_eda",
    "resultHeight": 357
   },
   "outputs": [],
   "source": [
    "final_features_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2987e3dd-fdd1-4968-ad63-de06e7580713",
   "metadata": {
    "language": "python",
    "name": "heatmap",
    "resultHeight": 1661
   },
   "outputs": [],
   "source": [
    "sns.heatmap(final_features_df[list(final_features_df.describe())].corr(), annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a666342-82da-41f4-8ddd-62751b89ab8f",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "churned_non_churned",
    "resultHeight": 60
   },
   "outputs": [],
   "source": [
    "y = features_df['LOGIN_NEXT_7_DAYS']\n",
    "churned_data = final_features_df[y == 0]\n",
    "non_churned_data = final_features_df[y == 1]\n",
    "zero_class_count = len(churned_data)\n",
    "one_class_count = len(non_churned_data)\n",
    "print(zero_class_count)\n",
    "print(one_class_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28157c7b-5d90-445c-9493-d29febb2b3a2",
   "metadata": {
    "collapsed": false,
    "name": "model_training",
    "resultHeight": 74
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c72ff1-e1ef-4e08-9422-e7939b9fbbc6",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "save_final_features",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# save the dataset as ROLLING_CHURN_FEATURES\n",
    "final_features_df = session.write_pandas(df=features_df.reset_index(), \\\n",
    "                     table_name=\"ROLLING_CHURN_FEATURES\", database=\"PLAYER_360\", schema=\"APP\", \\\n",
    "                     quote_identifiers=False,\n",
    "                     auto_create_table=True,\n",
    "                     overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0bce3a-1f63-484c-9ec1-731d18bdaae6",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "save_to_pred_features",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "to_pred_df = session.write_pandas(df=to_pred_df.reset_index(), \\\n",
    "                     table_name=\"TO_BE_PREDICTED_CHURN_FEATURES\", database=\"PLAYER_360\", schema=\"APP\", \\\n",
    "                     quote_identifiers=False,\n",
    "                     auto_create_table=True,\n",
    "                     overwrite=True).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd43470-1bf8-4928-9c1d-cec13a5661cc",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "load_sessions_table",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "final_features_df = session.table(\"PLAYER_360.APP.ROLLING_CHURN_FEATURES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a3242d-1cea-45b7-a356-8cf4baf95021",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "train_test_split",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "# split the dataset into test and train\n",
    "training, testing = final_features_df.random_split(weights=[0.8, 0.2], seed=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dec5b44-55dd-41e2-b09f-1fa72eeef8e4",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "model_creation",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "Target = ['LOGIN_NEXT_7_DAYS']\n",
    "Output_label = ['PREDICTED_CHURN']\n",
    "Features_label = [\n",
    "    \"TOTAL_SESSION_DURATION_ROLLING_30_DAYS\",\n",
    "    \"TOTAL_SESSIONS_ROLLING_30_DAYS\",\n",
    "    \"AVERAGE_SESSION_LEN_ROLLING_30_DAYS\",\n",
    "    \"TOTAL_POINTS_ROLLING_30_DAYS\",\n",
    "    \"AVERAGE_POINTS_PER_SESSION_ROLLING_30_DAYS\",\n",
    "    \"TOTAL_PURCHASE_AMOUNT_ROLLING_30_DAYS\",\n",
    "    \"TOTAL_PURCHASES_ROLLING_30_DAYS\",\n",
    "    \"AVG_PURCHASE_AMOUNT_ROLLING_30_DAYS\",\n",
    "    \"TOTAL_ADS_ROLLING_30_DAYS\",\n",
    "    \"AD_CONVERSION_RATE_ROLLING_30_DAYS\",\n",
    "    \"TOTAL_AD_ENGAGEMENT_TIME_ROLLING_30_DAYS\",\n",
    "    \"AVERAGE_ENGAGEMENT_TIME_ROLLING_30_DAYS\"\n",
    "]\n",
    "\n",
    "model = XGBClassifier(\n",
    "    input_cols=Features_label,\n",
    "    label_cols=Target,\n",
    "    output_cols=Output_label,\n",
    "    scale_pos_weight= zero_class_count/one_class_count, # replace with zero_class_count/ one_class_count\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47b4bb8-cd8b-442c-a2d6-5a297118d14a",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "model_fit_training",
    "resultHeight": 1709
   },
   "outputs": [],
   "source": [
    "training_df = training.to_pandas()\n",
    "model.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa633ec6-ab81-40dd-a7d7-f6cfaeb6607e",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": true,
    "language": "python",
    "name": "predictions",
    "resultHeight": 339
   },
   "outputs": [],
   "source": [
    "testing_df =testing.to_pandas()\n",
    "predictions = model.predict_proba(testing_df)\n",
    "true_labels = testing_df['LOGIN_NEXT_7_DAYS']\n",
    "churn_likelihood = predictions[['PREDICT_PROBA_0','PREDICT_PROBA_1']]\n",
    "churn_likelihood.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a743ec0-4813-4f30-8746-e8e9f48f7b4a",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "churn_metrics",
    "resultHeight": 239
   },
   "outputs": [],
   "source": [
    "# if the anamolous class (0) has probability >= .5, then didn't login in next 7 days\n",
    "predicted_churn = [0 if p >= .4 else 1 for p in churn_likelihood['PREDICT_PROBA_0']]\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_churn)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(true_labels, predicted_churn)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09112ffe-90ee-45e1-8a28-ce18cd77b449",
   "metadata": {
    "collapsed": false,
    "name": "model_registry",
    "resultHeight": 74
   },
   "source": [
    "# Log the Model in the Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77624403-6383-4406-86f1-ae88750b66e6",
   "metadata": {
    "language": "sql",
    "name": "switch_to_app_to_save_model",
    "resultHeight": 112
   },
   "outputs": [],
   "source": [
    "USE SCHEMA APP;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce771b-31fd-4fe9-9c54-35feebb10c15",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "log_model",
    "resultHeight": 97
   },
   "outputs": [],
   "source": [
    "from snowflake.ml.registry import Registry\n",
    "\n",
    "reg = Registry(session=session)\n",
    "\n",
    "MODEL_NAME = \"Player360_RollingChurn_Classifier\"\n",
    "MODEL_VERSION = \"v1\"\n",
    "\n",
    "X_train = training_df[Features_label][:1000]\n",
    "\n",
    "mv = reg.log_model(model,\n",
    "                   model_name=MODEL_NAME,\n",
    "                   version_name=MODEL_VERSION,\n",
    "                   options={\n",
    "                       \"case_sensitive\": True,\n",
    "                       \"enable_explainability\": True\n",
    "    },\n",
    "                    sample_input_data=X_train,\n",
    "                    target_platforms=[\"WAREHOUSE\"]\n",
    ")\n",
    "\n",
    "mv.set_metric(\"confusion_matrix\", cm.tolist())\n",
    "mv.set_metric(\"classification_report\", report)\n",
    "\n",
    "mv.comment = \"This is the first iteration of our Rolling Churn Classification model.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89155bc-a8a9-4eb4-af89-1650f8f68684",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "check_models",
    "resultHeight": 112,
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg.show_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7b4f94-fc5d-44ee-8b9d-8a53976af127",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": true,
    "language": "python",
    "name": "test_run",
    "resultHeight": 239
   },
   "outputs": [],
   "source": [
    "X_test = testing.select(Features_label).limit(10)\n",
    "mv.run(X_test, function_name=\"predict_proba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6771d7d2-6134-402e-8150-9eff898f047f",
   "metadata": {
    "collapsed": false,
    "name": "model_explainability",
    "resultHeight": 74
   },
   "source": [
    "# Model Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e61e17c-ccc8-4d48-882d-005b59230325",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": true,
    "language": "python",
    "name": "mv_explanations_exp",
    "resultHeight": 239
   },
   "outputs": [],
   "source": [
    "mv_explanations = mv.run(X_test, function_name=\"explain\")\n",
    "mv_explanations =mv_explanations.to_pandas()\n",
    "mv_explanations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190c55eb-f311-49a8-80ea-0c73195982e2",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": true,
    "language": "python",
    "name": "shap_plot",
    "resultHeight": 239
   },
   "outputs": [],
   "source": [
    "shap_exp = shap._explanation.Explanation(mv_explanations.values, feature_names=mv_explanations.columns)\n",
    "shap.plots.bar(shap_exp)"
   ]
  }
 ]
}
